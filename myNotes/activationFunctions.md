# Activation Functions

It is a function applied to the neurons in a layer during the prediction.

## Constraints

<ul>
    <li>The function must be continuous and infinite in domain.</li>
    <li>Good activation functions are monotonic, never changing direction</li>
    <li>Good activation functions are nonlinear (they squiggle or turn)</li>
    <li>
        Good activation functions (and their derivatives) should be efficiently computable.
    </li>
</ul>

## Typical activation functions

### Sigmoid

![](/images/sigmoid.png "sigmoid")

## tanh

It is better for hidden layers

![](/images/tanh.png "tanh")
